# TinyEval
æ‰‹æ“LLMè¯„æµ‹ç³»ç»Ÿç›´æ’­ï¼š[ç›´æ’­é“¾æ¥](https://meeting.tencent.com/v2/cloud-record/share?id=8b9cf6ca-add6-477b-affe-5b62e2d8f27e&from=3)

ä¸‹é¢æˆ‘ä¼šå¸¦é¢†å¤§å®¶ä¸€æ­¥ä¸€æ­¥å®ç°ä¸€ä¸ªç®€å•çš„LLMè¯„æµ‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ˜¯ä¸€ä¸ªåŒé˜¶æ®µçš„è¯„æµ‹ä½“ç³»ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º`TinyEval`ï¼ŒåŒ…å«äº†`LLM`é€šç”¨è¯„æµ‹çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œæ”¯æŒç”Ÿæˆå¼ã€åˆ¤åˆ«å¼ã€é€‰åˆ™å¼è¯„æµ‹é—®é¢˜ï¼Œæ¡†æ¶ä¸»è¦åŒ…å«`inference`ä¸`eval`éƒ¨åˆ†ï¼Œç›®çš„æ˜¯ä¸ºäº†å¸®åŠ©å¤§å®¶æ›´å¥½çš„åŠ›å³LLMè¯„æµ‹çš„åŸç†ä¸å®ç°ã€‚

## 1.é¡¹ç›®çš„Motivationæ˜¯ä»€ä¹ˆ?
åˆå…¥`LLM`å¤§é—¨ï¼Œä½ æ˜¯å¦æœ‰ç±»ä¼¼çš„å›°æƒ‘:

1. å„ä¸ªæ¨¡å‹çš„è¯„æµ‹æŒ‡æ ‡äº”èŠ±å…«é—¨?å°ç™½åˆå­¦è€…çœ‹ä¸æ‡‚,éš¾ä»¥å­¦ä¹ ?
2. è¯„æµ‹`metric`ä¸ä¼šé€‰,é™¤äº†`rouge`,`blue`æƒ³ä¸åˆ°å…¶ä»–çš„`metric`?
3. æƒ³è®©`LLM`åšé€‰æ‹©é¢˜,ä½†æ˜¯æ¨¡å‹è¾“å‡ºäº†ä¸€å¤§å †,å¦‚ä½•è¯„ä»·é€‰æ‹©èƒ½åŠ›? 
4. æ¨¡å‹äº”èŠ±å…«é—¨ï¼Œå‚åŸŸä»»åŠ¡ä¹Ÿäº”èŠ±å…«é—¨ã€‚é™¤äº†`human_eval`ä¹‹å¤–ï¼Œå¦‚ä½•å¯¹ä¸ªæ€§åŒ–çš„ä»»åŠ¡æä¾›æœ‰è¯´æœåŠ›çš„å®šé‡æ€§èƒ½æŒ‡æ ‡?  

So, æœ¬é¡¹ç›®å°†é€ä¸ªä¸ºä½ è§£å¼€ä¸Šè¿°çš„å›°æƒ‘ï¼

## 2.Evaléƒ½åŒ…å«å“ªäº›æµç¨‹?
é¦–å…ˆè¦æ˜ç¡®è¯„æµ‹ä»»åŠ¡çš„åŸºç¡€`pipeline`ã€‚ä¸‹å›¾æ˜¯è¯„æµ‹ä»»åŠ¡çš„ç®€è¦æµç¨‹ï¼š 

<div align=center>
    <img src="./Eval/docs/compass.png" style="width:70%;">
</div>


- é¦–å…ˆï¼Œæ ¹æ®ç›®æ ‡æ•°æ®é›†çš„ä»»åŠ¡ç±»å‹æŒ‡å®šåˆç†çš„è¯„æµ‹`metric`.
- æ ¹æ®ç›®æ ‡æ•°æ®çš„å½¢å¼æ€»ç»“æ¨¡å‹å¼•å¯¼`prompt`.
- æ ¹æ®æ¨¡å‹åˆæ­¥é¢„æµ‹ç»“æœé‡‡çº³åˆç†çš„æŠ½å–æ–¹å¼.
- å¯¹ç›¸åº”çš„`pred`ä¸`anwser`è¿›è¡Œå¾—åˆ†è®¡ç®—. 

OKï¼Œä¸Šè¿°è¿™äº›ä¹Ÿå°±æ˜¯TinyEvalä»“åº“çš„æ‰€æœ‰æ¨¡å—å†…å®¹ã€‚

## 3.æ”¯æŒçš„è¯„æµ‹æ•°æ®é›†ä¸è¯„æµ‹Metric.
æ‰€é‡‡ç”¨çš„æ•°æ®é›†åœ¨è¿™é‡Œ[here](./Eval/dataset/),ç›®å‰æœ‰çš„æ•°æ®é›†ä¸ç±»å‹åŒ…å«(åç»­ä¼šæŒç»­æ›´æ–°!): 

|name|type|metric|
|---|---|---|
|multi_news|é•¿æ–‡æœ¬é—®ç­”|Rouge|
|multifieldqa_zh|çŸ­æ–‡æœ¬é—®ç­”|F1|
|trec|ç”Ÿæˆå¼é€‰åˆ™|accuracy|

å¤§å®¶å¯ä»¥æŒ‰ç…§éœ€è¦çš„ä»»åŠ¡è¿›è¡Œæ¢ç´¢ï¼Œæ¥ä¸‹æ¥æˆ‘ä¹Ÿä¼šæ‰‹æŠŠæ‰‹ä¸ºå¤§å®¶è®²è§£è¯„æµ‹æ­¥éª¤ï¼

## è¯„æµ‹è¿‡ç¨‹ä»‹ç».
çœ‹åˆ°äº†ä¸Šé¢çš„æŒ‡æ ‡æ˜¯å¦æœ‰è¿™æ ·çš„ç–‘é—®:  
- What? `F1` ä¸æ˜¯åˆ†ç±»æŒ‡æ ‡ï¼Œæ€ä¹ˆè·‘`llm`å»äº†?
- `accuracy`ä¸æ˜¯è¦åˆ†`label`æ ‡ç­¾çš„å—?æ€ä¹ˆè·‘ç”Ÿæˆå¼é‡Œæ¥äº†?  

Okey,è¿™ä¸€èŠ‚ä¸»è¦å°±æ˜¯è®²è§£ä¸Šè¿°çš„ç–‘é—®,å¦‚æœæœ‰åŸºç¡€çš„åŒå­¦ï¼Œå¯ä»¥å…ˆè‡ªè¡Œæ¢ç´¢[ç›¸å…³ä»£ç ](./Eval/metrics.py)  

### 1. ç”Ÿæˆå¼çš„F1

#### 1.1 æ¨¡å‹æ¨ç†
- é¦–å…ˆ,å¯¹äºä¸€ä¸ªè¯„æµ‹æ•°æ®é›†,æˆ‘ä»¬é¦–å…ˆè¦æ„é€ å¼•å¯¼prompt,å³å¼•å¯¼llmç”Ÿæˆæˆ‘ä»¬æƒ³è¦çš„ç­”æ¡ˆã€‚å¯¹äºå·²æœ‰çš„æ•°æ®é›†,å¤§éƒ¨åˆ†éƒ½æä¾›äº†ç›¸åº”çš„prompt,åœ¨è‡ªå·±æ•°æ®é›†è¯„æµ‹æ—¶,ä¹Ÿå¯è‡ªè¡Œè®¾è®¡ã€‚ä»¥`multifieldqa_zh`ä¸ºä¾‹,å…¶å¼•å¯¼promptä¸º:
```
é˜…è¯»ä»¥ä¸‹æ–‡å­—å¹¶ç”¨ä¸­æ–‡ç®€çŸ­å›ç­”ï¼š\n\n{context}\n\nç°åœ¨è¯·åŸºäºä¸Šé¢çš„æ–‡ç« å›ç­”ä¸‹é¢çš„é—®é¢˜ï¼Œåªå‘Šè¯‰æˆ‘ç­”æ¡ˆï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å­—è¯ã€‚\n\né—®é¢˜ï¼š{input}\nå›ç­”ï¼š
```
- ä¹‹å,å†æŒ‡å®šæ¨¡å‹çš„è¾“å…¥é•¿åº¦,åœ¨æ­¤ä¸»è¦æ˜¯è§„å®šæ¯æ¬¡é€è¿›æ¨¡å‹å¤šå°‘tokenæ•°,ä¸€èˆ¬ä¸ºäº†è¿½æ±‚æ€§èƒ½å¯ä»¥è®¾ç½®ä¸ºæ¨¡å‹æœ€å¤§é•¿åº¦,å¯ä»¥åœ¨ä¸‹è½½å¥½çš„æ¨¡å‹æ–‡ä»¶é‡Œé¢çš„`config.json`é‡Œé¢çš„"max_position_embeddings"æŸ¥è¯¢,ä¹Ÿå¯ä»¥ä¸è®¾ç½®ä½œä¸ºé»˜è®¤æœ€å¤§é•¿åº¦.ä½†æœ¬é¡¹ç›®è®¾ç½®ä¸ºäº†2048,ä¸»è¦ä¸ºäº†æ¼”ç¤ºä½¿ç”¨~  

- ä¹‹åå°±æ˜¯åˆ›å»ºmodelæ•´ä½“,åœ¨æ­¤æˆ‘å¯¹æ¨¡å‹æ•´ä½“åˆ›å»ºäº†ä¸€ä¸ªclass,å¤§å®¶å¯ä»¥å‚è€ƒå¯¹å…¶ä»–ä»»æ„çš„modelè¿›è¡Œç»„è£…:
```python
class BaseLLM:
    def __init__(self, path: str, model_name: str) -> None:
        self.path = path
        self.model_name = model_name

    def build_chat(self, tokenizer: str, prompt: str, model_name: str):
        pass

    def load_model_and_tokenizer(self, path: str, model_name: str, device):
        pass

    def post_process(self, response: str, model_name: str):
        pass

    def get_pred(self, data: list, max_length: int, max_gen: int, prompt_format: str, device, out_path: str):
        pass
```
- å‚æ•°è§£è¯»,build_chatä¸ºä½¿ç”¨æ¨¡å‹å›ºæœ‰çš„æ•°æ®åŠ è½½å½¢å¼,ä»¥`internlm2`ä¸ºä¾‹,å…¶ä¸º
```python
def build_chat(self, prompt):
        prompt = f'<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n'
        return prompt
```
- modelä¸tokenizerä¸ç”¨å¤šè¯´,åå¤„ç†æ ¹æ®modelçš„å½¢å¼é€‰æ‹©æ€§åˆ¤æ–­æ˜¯å¦éœ€è¦ï¼Œé‡ç‚¹è®²ä¸€ä¸‹`get_pred`å‡½æ•°ï¼š

```python
def get_pred(self, data, max_length, max_gen, prompt_format, device, out_path):
        model, tokenizer = self.load_model_and_tokenizer(self.path, device)
        for json_obj in tqdm(data):
            prompt = prompt_format.format(**json_obj)
            # åœ¨ä¸­é—´æˆªæ–­,å› ä¸ºä¸¤å¤´æœ‰å…³é”®ä¿¡æ¯.
            tokenized_prompt = tokenizer(prompt, truncation=False, return_tensors="pt").input_ids[0]
            if len(tokenized_prompt) > max_length:
                half = int(max_length/2)
                prompt = tokenizer.decode(tokenized_prompt[:half], skip_special_tokens=True)+tokenizer.decode(tokenized_prompt[-half:], skip_special_tokens=True)

            prompt = self.build_chat(prompt)

            input = tokenizer(prompt, truncation=False, return_tensors="pt").to(device)
            # è¡¨ç¤ºå–‚è¿›å»çš„tokensçš„é•¿åº¦
            context_length = input.input_ids.shape[-1]
            eos_token_id = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(["<|im_end|>"])[0]]

            output = model.generate(
                **input,
                max_new_tokens=max_gen,
                do_sample=False,
                temperature=1.0,
                eos_token_id=eos_token_id,
            )[0]
            
            pred = tokenizer.decode(output[context_length:], skip_special_tokens=True)
            pred = self.post_process(pred)
            
            with open(out_path, "a", encoding="utf-8") as f:
                json.dump({"pred": pred, "answers": json_obj["answers"], "all_classes": json_obj["all_classes"], "length": json_obj["length"]}, f, ensure_ascii=False)
                f.write('\n')
``` 

- æœ‰çš„åŒå­¦å¯èƒ½ä¼šé—®,ä¸ºå•¥è¦æ•´è¿™ä¹ˆä¸€å¤§ä¸²,ç›´æ¥ç”¨`model.chat()`ä¸é¦™å—?? 
- Okey!è¿™ä¸ªå‡½æ•°å°±å‘Šè¯‰äº†ä½ ç­”æ¡ˆã€‚åŸå› å°±åœ¨äºæˆªæ–­ç­–ç•¥,å¯¹äºæ¨¡å‹è€Œè¨€,å°¤å…¶æ˜¯åˆ¶å®šäº†è¾“å…¥çš„é•¿åº¦,å¦‚æœä½¿ç”¨é˜¶æ®µå‘½ä»¤åˆ™å…¶ä¼šåœ¨è¾“å…¥çš„æœ«å°¾è¿›è¡Œé˜¶æ®µ,ä½†ç”±äºå¼•å¯¼æ€§`prompt`çš„å­˜åœ¨,åœ¨`inputs`çš„ä¸¤ç«¯å‡æœ‰å…³é”®ä¿¡æ¯,æ•…éœ€è¦å¯¹ä¸¤ç«¯çš„ä¿¡æ¯è¿›è¡Œä¿ç•™,å¯¹ä¸­é—´éƒ¨ä½è¿›è¡Œæˆªæ–­æ“ä½œ,æ‰èƒ½æœ€å¤§é™åº¦åœ°æŠ±æŒè¾“å‡ºæ•ˆæœ!

> tips: get_predéƒ¨åˆ†,å¯ä»¥å‚è€ƒå„å¤§æ¨¡å‹å„è‡ªçš„`model`ç›¸å…³è„šæœ¬ä¸­çš„`chat`å‡½æ•°(`internlm2`åœ¨`modeling_internlm2.py`é‡Œé¢),ä¹Ÿå¯ä»¥æ›´å¥½çš„ç†è§£åŸå§‹æ–‡æœ¬è¾“å…¥ä¸ç»“æ„åŒ–æ¨¡å‹è¾“å‡ºã€‚

#### 1.2 ç»“æœè¯„æµ‹
ç›´æ¥showä¾‹å­:
```
"pred": "57081.86å…ƒ", "answers": "äººæ°‘å¸57081.86å…ƒã€‚"
```
- é¦–å…ˆ,ç»è¿‡æ•°æ®æ¸…æ´—ä¸`jieba`åˆ†è¯,å°†çŸ­å¥åˆ†ä¸ºè¯ç»„,ä»¥ç¤ºä¾‹æ–‡æœ¬ä¸ºä¾‹,ç»è¿‡åˆ†è¯ä¸å»æ‰æ ‡ç‚¹ç¬¦å·ç­‰æ“ä½œ,å¾—åˆ°ä¸‹åˆ—è¾“å‡º:
```
"pred": ['5708186', 'å…ƒ'], "answers": ['äººæ°‘å¸', '5708186', 'å…ƒ']"
```
å°†ä¸Šè¿°çš„ä¸¤ä¸ª"å¹²å‡€"çš„è¾“å‡ºé€å…¥`f1`è¯„åˆ†å‡½æ•°å¦‚ä¸‹:
```python
def f1_score(prediction, ground_truth, **kwargs):
    # Counterä»¥dictçš„å½¢å¼å­˜å‚¨å„ä¸ªå¥å­å¯¹åº”çš„è¯ä¸å…¶å¯¹åº”ä¸ªæ•°,&æ“ä½œç¬¦è¿”å›ä¸¤ä¸ªCounterä¸­å…±åŒçš„å…ƒç´ çš„é”®å€¼å¯¹
    common = Counter(prediction) & Counter(ground_truth)
    # æ˜¾ç¤ºpredictionä¸gtçš„å…±åŒå…ƒç´ çš„ä¸ªæ•°  
    num_same = sum(common.values())                       
    if num_same == 0:
        return 0
    # å³æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°é‡ä¸æ€»é¢„æµ‹æ ·æœ¬æ•°é‡çš„æ¯”å€¼
    precision = 1.0 * num_same / len(prediction)
    # æ¨¡å‹æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬æ•°é‡ä¸æ€»å®é™…æ ·æœ¬æ•°é‡çš„æ¯”å€¼         
    recall = 1.0 * num_same / len(ground_truth)           
    f1 = (2 * precision * recall) / (precision + recall)
    return f1
```
- é¦–å…ˆè®°å½•ä¸¤ä¸ªlistä¸­ç›¸åŒçš„å…ƒç´ ,å†ç»Ÿè®¡ç›¸åŒçš„å…ƒç´ çš„æ€»æ•°,æœ€ç»ˆå†æŒ‰ç…§precisionä¸recallçš„å®šä¹‰åˆ†åˆ«è®¡ç®—ç›¸åº”çš„åˆ†æ•°ã€‚  
- ç„¶åå°±å¾—åˆ°è¯¥ç»“æœçš„å¯¹åº”åˆ†æ•°å•¦,æœ€åå†å°†æ‰€æœ‰çš„ç»“æœå–å¹³å‡å€¼,å³å¾—åˆ°è¯¥`task`çš„`F1_score`

### 2.æ€è€ƒ
å½“ç„¶ï¼Œè¿™äº›åªæ˜¯åŸºç¡€çš„`metric`è¯„æµ‹æŒ‡æ ‡ï¼Œæˆ–è®¸ç»†å¿ƒçš„ä½ å·²ç»å‘ç°äº†ç›¸åº”çš„æ¼æ´ï¼Œæ¯”å¦‚åœ¨ä¸Šè¿°é¢„æµ‹ä¸­ï¼Œç›¸æ¯”è¾ƒçš„ç»“æœéƒ½æ˜¯ç»è¿‡äº†ç›¸åº”çš„è§„åˆ™æŠ½å–çš„ï¼Œå¦‚æœå‡ºç°äº†æ¯”å¦‚`answer`æ˜¯"å¦é—¨å¤§å­¦",è€Œ`pred`æ˜¯"ä¸æ˜¯å¦é—¨å¤§å­¦"/"å¦å¤§",åˆ™äºŒè€…çš„ç»“æœæŒ‰ç…§å½“å‰çš„è¯„åˆ†æŒ‡æ ‡åˆ™æœ‰å¤±åé¢‡ã€‚
    
å½“ç„¶,æ›´åŠ å‡†ç¡®çš„è¯„æµ‹metricä¹Ÿæ˜¯å­¦æœ¯ç•Œä¸€ç›´åŠªåŠ›çš„ç›®æ ‡,æœ¬é¡¹ç›®ä¹Ÿä¼šåŠæ—¶è·Ÿè¿›æ›´åŠ å…ˆè¿›çš„è¯„æµ‹ç­–ç•¥,ä¹Ÿæ¬¢è¿å¤§ä½¬PRï¼ï¼

## ğŸ˜†æˆåŠŸè¿è¡Œ!

### 1. get inference results
```python
python inference.py
```

### 2. get eval results
```python
python eval.py
```

## support metrics
1. F1 score
2. rouge-series/blue-series
3. accuracy

## æ”¯æŒè‡ªå®šä¹‰è¯„æµ‹
æˆ‘ä»¬repoä¹Ÿæ”¯æŒè‡ªå®šä¹‰è¯„æµ‹ï¼Œå¦‚æœè¿›è¡Œäº†è‡ªå®šä¹‰sftæ•°æ®ï¼Œæˆ‘ä»¬å‘½åä¸º`custom_zh`,æˆ–å¦‚æœæ˜¯è‹±æ–‡çš„è¯å¯ä»¥ä¸º`custom_en`,æ•°æ®å½¢å¼ä¸sftæ ¼å¼ä¸€è‡´ï¼Œå¦‚ä¸‹:  
```python
{
    "instruction": "å‡è®¾ä½ æ˜¯çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›",
    "input": "ä½ æ˜¯è°?",
    "output": "è‡£å¦¾æ˜¯ç”„å¬›ï¼Œå®¶çˆ¶æ˜¯å¤§ç†å¯ºå°‘å¿ã€‚"
}
```
å³å¯æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†çš„è¯„æµ‹~

## Reference & Acknowledgment
[LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding](https://arxiv.org/abs/2308.14508)
